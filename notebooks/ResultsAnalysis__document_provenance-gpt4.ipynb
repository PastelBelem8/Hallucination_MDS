{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef216c0a-f6ec-4852-8632-095366f9f5ad",
   "metadata": {},
   "source": [
    "In this notebook, we investigate the attribution of the hallucinated insights to the different documents. To do so, we will propose a variant of the substring matching procedure used in the GPT-4 paper in the context of data contamination. \n",
    "Our variant however, considers every 50-character subtring (or shorter if the insight is smaller) that starts at a specific word in the insight, and checks for its occurrent in an input document at position i in the input. If we say that the insight belongs to that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e789ac5-e70d-4abe-9560-4854ca143adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbelem/anaconda3/envs/emnlp-2024/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json, glob, string, pickle, tqdm\n",
    "\n",
    "import sys; sys.path.append(\"../src\")\n",
    "from mitigation_base import SharedOnlyFilter\n",
    "from utils_io import read_json\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MultipleLocator, PercentFormatter\n",
    "\n",
    "from plotting_utils import *\n",
    "\n",
    "matplotlib.rc('font', family='serif')\n",
    "\n",
    "FULL_WIDTH = 6.75133\n",
    "COL_WIDTH  = 3.25063"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92d377-2b87-4f3e-af4a-75764bc447f9",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1a4b4a-d80c-4624-b50d-e1d1e7d02763",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBINATION_SIZE = 5\n",
    "METRIC = \"metric__bidirectional\"\n",
    "\n",
    "DOMAINS = (\n",
    "    \"news\",\n",
    "    \"conv\",\n",
    ")\n",
    "\n",
    "MODELS = (\n",
    "    \"accounts/fireworks/models/llama-v3p1-70b-instruct\",\n",
    "    \"gpt-4o-2024-05-13\",\n",
    "    \"gpt-3.5-turbo-0125\",\n",
    "    \"accounts/fireworks/models/qwen2-72b-instruct\",\n",
    "    \"gemini-1.5-flash\",\n",
    ")\n",
    "\n",
    "PROMPT_TYPES = (\n",
    "    \"subtopic\", \n",
    "    \"subtopic_trustworthy\",\n",
    ")\n",
    "\n",
    "create_doc_matcher = partial(\n",
    "    SharedOnlyFilter,\n",
    "    substr_len=50, \n",
    "    use_lowercase=True,\n",
    "    remove_stopwords=False,\n",
    "    remove_punctuation=True,\n",
    "    # ^note: tweak parameters above to your taste\n",
    "    classname=\"contamination_base.SubstringMatch\",\n",
    "    shared_by_or_more=2,\n",
    "    cache_only=False,\n",
    ")\n",
    "# ^Note: use ``create_doc_matcher()`` to obtain a new instance of document matcher\n",
    "# this is necessary because of side modifications that occur when processing\n",
    "# the documents of a specific file\n",
    "# (since the documents are independent we shouldnt observe any clash in terms\n",
    "# of uuids, but better be safe than sorrow :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc11d272-1060-4b44-90a1-7cc7838dff35",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f12c1c7-0103-4096-8c8f-370d1debe4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(data, cache_dir: str, combination_size: int, exclude_insights_with_no_matches: bool=True): \n",
    "    doc_matcher = create_doc_matcher(cache_dir=cache_dir)\n",
    "    doc_matcher.init_cache()\n",
    "    match_results = doc_matcher.run(data)\n",
    "    #^Note: match results consists of the matches for every predicted insight\n",
    "    # (regardless of its correctness label).\n",
    "    # Specifically, it is located in: \n",
    "    # pd.DataFrame(match_results[\"postprocessing__SharedOnlyFilter\"])[\"matches\"]\n",
    "    # Therefore, we need to match it with our correctness labels\n",
    "    match_results_df = pd.DataFrame(match_results[\"postprocessing__SharedOnlyFilter\"])\n",
    "\n",
    "    doc_attribution_results = defaultdict(list)\n",
    "    for _, row in match_results_df.iterrows():\n",
    "        if exclude_insights_with_no_matches and len(row[\"matches\"]) <= 0:\n",
    "            continue\n",
    "        \n",
    "        for i in range(combination_size):\n",
    "            doc_attribution_results[\"response_id\"].append(row[\"response_id\"])        \n",
    "            doc_attribution_results[\"pred_rank\"].append(row[\"pred_rank\"])   \n",
    "            doc_attribution_results[\"pred_text\"].append(row[\"pred_text\"])   \n",
    "            doc_attribution_results[\"pred_uuid\"].append(row[\"pred_uuid\"])\n",
    "            doc_attribution_results[\"doc_position\"].append(i)\n",
    "            doc_attribution_results[\"is_present\"].append(int(i in row[\"matches\"]))\n",
    "    \n",
    "    doc_attribution_results = pd.DataFrame(doc_attribution_results)\n",
    "    return doc_attribution_results\n",
    "\n",
    "\n",
    "def get_correctness_labels(labels: List[str], examples: pd.DataFrame) -> pd.DataFrame:\n",
    "    a1 = examples.set_index([\"response_id\", \"pred_uuid\"]).copy()\n",
    "    a2 = pd.DataFrame(labels)\n",
    "    a2 = a2.rename({\"response_idx\": \"response_id\"}, axis=1).set_index([\"response_id\", \"pred_uuid\"])\n",
    "    coverage_labels = a1.join(a2, how=\"left\")\n",
    "    coverage_labels[\"coverage\"] = coverage_labels[\"coverage\"].fillna(\"NO_COVERAGE\")\n",
    "    return coverage_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d433b187-8f19-47da-9929-83c74743f5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 87.36it/s] \n",
      "50it [00:00, 117.05it/s]\n",
      "50it [00:00, 107.30it/s]\n",
      "50it [00:00, 116.27it/s]\n",
      "50it [00:00, 144.70it/s]\n",
      "50it [00:00, 130.46it/s]\n",
      "50it [00:00, 121.24it/s]\n",
      "50it [00:00, 129.20it/s]\n",
      "50it [00:00, 266.78it/s]\n",
      "50it [00:00, 240.26it/s]\n",
      "50it [00:00, 228.11it/s]\n",
      "50it [00:00, 292.52it/s]\n",
      "50it [00:00, 93.31it/s] \n",
      "50it [00:00, 140.01it/s]\n",
      "50it [00:00, 128.70it/s]\n",
      "50it [00:00, 133.17it/s]\n",
      "100it [00:01, 98.38it/s]\n",
      "100it [00:00, 101.16it/s]\n",
      "100it [00:00, 131.71it/s]\n",
      "100it [00:00, 102.35it/s]\n",
      "50it [00:00, 184.36it/s]\n",
      "50it [00:00, 153.92it/s]\n",
      "50it [00:00, 143.54it/s]\n",
      "50it [00:00, 166.02it/s]\n",
      "50it [00:00, 196.32it/s]\n",
      "50it [00:00, 158.71it/s]\n",
      "50it [00:00, 162.85it/s]\n",
      "50it [00:00, 170.98it/s]\n",
      "50it [00:00, 294.10it/s]\n",
      "50it [00:00, 275.36it/s]\n",
      "50it [00:00, 285.19it/s]\n",
      "50it [00:00, 349.13it/s]\n",
      "50it [00:00, 171.89it/s]\n",
      "50it [00:00, 167.19it/s]\n",
      "50it [00:00, 161.73it/s]\n",
      "50it [00:00, 153.76it/s]\n",
      "100it [00:00, 102.48it/s]\n",
      "100it [00:00, 116.69it/s]\n",
      "100it [00:00, 167.14it/s]\n",
      "100it [00:00, 123.60it/s]\n",
      "100it [00:00, 124.64it/s]\n",
      "100it [00:01, 99.18it/s]\n",
      "100it [00:00, 134.52it/s]\n",
      "100it [00:01, 94.80it/s]\n",
      "100it [00:00, 115.02it/s]\n",
      "100it [00:00, 137.01it/s]\n",
      "100it [00:00, 149.39it/s]\n",
      "100it [00:00, 138.80it/s]\n",
      "100it [00:00, 122.76it/s]\n",
      "100it [00:00, 129.61it/s]\n",
      "100it [00:00, 258.41it/s]\n",
      "100it [00:00, 275.40it/s]\n",
      "100it [00:00, 297.24it/s]\n",
      "100it [00:00, 230.32it/s]\n",
      "100it [00:00, 259.31it/s]\n",
      "100it [00:00, 111.51it/s]\n",
      "100it [00:00, 112.44it/s]\n",
      "100it [00:00, 122.17it/s]\n",
      "100it [00:01, 94.13it/s] \n",
      "100it [00:01, 82.98it/s]\n",
      "100it [00:00, 124.59it/s]\n",
      "100it [00:00, 139.11it/s]\n",
      "100it [00:00, 149.68it/s]\n",
      "100it [00:01, 67.85it/s]\n",
      "100it [00:01, 86.93it/s]\n",
      "100it [00:00, 169.55it/s]\n",
      "100it [00:00, 133.02it/s]\n",
      "100it [00:00, 180.16it/s]\n",
      "100it [00:00, 137.13it/s]\n",
      "100it [00:00, 153.32it/s]\n",
      "100it [00:00, 218.86it/s]\n",
      "100it [00:00, 225.23it/s]\n",
      "100it [00:00, 235.88it/s]\n",
      "100it [00:00, 167.42it/s]\n",
      "100it [00:00, 207.15it/s]\n",
      "100it [00:00, 376.19it/s]\n",
      "100it [00:00, 342.72it/s]\n",
      "100it [00:00, 409.11it/s]\n",
      "100it [00:00, 280.83it/s]\n",
      "100it [00:00, 363.34it/s]\n",
      "100it [00:00, 147.63it/s]\n",
      "100it [00:00, 167.33it/s]\n",
      "100it [00:00, 174.93it/s]\n",
      "100it [00:01, 97.12it/s] \n",
      "100it [00:00, 146.60it/s]\n",
      "100it [00:00, 216.87it/s]\n",
      "100it [00:00, 186.86it/s]\n",
      "100it [00:00, 245.16it/s]\n",
      "100it [00:01, 87.21it/s]\n",
      "100it [00:00, 135.77it/s]\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for domain in DOMAINS:\n",
    "    for prompt_type in PROMPT_TYPES:\n",
    "        for model in MODELS:\n",
    "            result_filepaths = glob.glob(f\"../outputs_{domain}/run_evals_postprocessing-multi-request/gpt-4o-mini-2024-07-18/results_some_shared/{prompt_type}/SummHay__combinations-10/{model}/topic_{domain}*__*examples*.json\")\n",
    "            if len(result_filepaths) > 5: \n",
    "                raise ValueError(\"Unexpected\")\n",
    "        \n",
    "            for path in result_filepaths:\n",
    "                data = read_json(path)\n",
    "                matches = get_matches(data, \n",
    "                                      combination_size=COMBINATION_SIZE,\n",
    "                                      exclude_insights_with_no_matches=True,\n",
    "                                      cache_dir=f\"./document_provenance/{domain}/{prompt_type}/combinations-{COMBINATION_SIZE}\",\n",
    "                                     )\n",
    "                matches = get_correctness_labels(\n",
    "                    labels=data[\"evaluation_assignments\"][\"metric__bidirectional\"][\"labels\"], \n",
    "                    examples=matches,\n",
    "                )\n",
    "                matches[\"domain\"] = domain\n",
    "                matches[\"prompt_type\"] = prompt_type\n",
    "                matches[\"model\"] = model.rpartition(\"/\")[-1]\n",
    "                all_results.append(matches.reset_index())\n",
    "            \n",
    "all_results = pd.concat(all_results).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee1bba-cac3-4d81-8110-05faa567ba95",
   "metadata": {},
   "source": [
    "## 1.1. Definition of correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7f8b44-69bf-4e03-a9c0-4710845c91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct(coverage, use_partial=True):\n",
    "    correct_labels = [\"FULL_COVERAGE\"]\n",
    "    if use_partial:\n",
    "        correct_labels.append(\"PARTIAL_COVERAGE\")\n",
    "    return coverage in correct_labels\n",
    "\n",
    "all_results[\"correct (fc+pc)\"] = all_results[\"coverage\"].apply(is_correct, use_partial=True)\n",
    "all_results[\"correct (fc)\"] = all_results[\"coverage\"].apply(is_correct, use_partial=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a1bcd-0424-4afd-a606-db96c1f0c8ab",
   "metadata": {},
   "source": [
    "### Correctness definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a205585-d1c1-4d64-9463-3182a3756ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_incorrect_fcpc = all_results[~all_results[\"correct (fc+pc)\"]]\n",
    "all_results_incorrect_fc = all_results[~all_results[\"correct (fc)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c1d1a-e6cf-45c3-9e37-65b9f349326a",
   "metadata": {},
   "source": [
    "## Subtopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62fbf3-381f-4954-9c19-00fe8c7bf8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type = \"subtopic\"\n",
    "subset = all_results_incorrect_fcpc[all_results_incorrect_fcpc[\"prompt_type\"] == prompt_type]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(COL_WIDTH, COL_WIDTH), dpi=300)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(f\"(a) news\", fontsize=10)\n",
    "\n",
    "subset_news = subset[subset[\"domain\"] == \"news\"]\n",
    "sns.lineplot(subset_news, x=\"doc_position\", y=\"is_present\", hue=\"model\", ax=ax)\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.10))\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "\n",
    "ax.grid(axis='y', which=\"major\", linewidth=1, linestyle='--', color=\"gray\")\n",
    "ax.get_legend().remove()\n",
    "remove_axes(ax)\n",
    "ax.set_ylim(0, 0.5)\n",
    "ax.set_ylabel(None)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(f\"(b) conv\", fontsize=10)\n",
    "subset_conv = subset[subset[\"domain\"] == \"conv\"]\n",
    "sns.lineplot(subset_conv, x=\"doc_position\", y=\"is_present\", hue=\"model\", ax=ax)\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.10))\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "\n",
    "ax.grid(axis='y', which=\"major\", linewidth=1, linestyle='--', color=\"gray\")\n",
    "\n",
    "ax.set_xlabel(\"Document Position\")\n",
    "ax.set_ylabel(None)\n",
    "\n",
    "ax.set_ylim((0.0, 0.5))\n",
    "ax.set_xlim((0.0, 9))\n",
    "ax.legend(loc=\"upper left\", ncols=2, bbox_to_anchor=(0.0, 1.0), fontsize=7.5)\n",
    "\n",
    "remove_axes(ax)\n",
    "adjust(fig, hspace=0.2)\n",
    "save_fig(fig, f\"both_domains__subtopic__fc+pc.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c88357-52b7-4c11-95b7-c173fd178ecd",
   "metadata": {},
   "source": [
    "### Subtopic trustworthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50d726b-a9a7-434b-8f98-7cea46148a89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results_incorrect_fcpc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubtopic_trustworthy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m subset \u001b[38;5;241m=\u001b[39m \u001b[43mall_results_incorrect_fcpc\u001b[49m[all_results_incorrect_fcpc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m prompt_type]\n\u001b[1;32m      4\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(COL_WIDTH, COL_WIDTH), dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m      6\u001b[0m ax \u001b[38;5;241m=\u001b[39m axes[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_results_incorrect_fcpc' is not defined"
     ]
    }
   ],
   "source": [
    "prompt_type = \"subtopic_trustworthy\"\n",
    "subset = all_results_incorrect_fcpc[all_results_incorrect_fcpc[\"prompt_type\"] == prompt_type]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(COL_WIDTH, COL_WIDTH), dpi=300)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(f\"(a) news\", fontsize=10)\n",
    "\n",
    "subset_news = subset[subset[\"domain\"] == \"news\"]\n",
    "sns.lineplot(subset_news, x=\"doc_position\", y=\"is_present\", hue=\"model\", ax=ax)\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.10))\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "\n",
    "ax.grid(axis='y', which=\"major\", linewidth=1, linestyle='--', color=\"gray\")\n",
    "ax.get_legend().remove()\n",
    "remove_axes(ax)\n",
    "ax.set_ylim(0, 0.5)\n",
    "ax.set_ylabel(None)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(f\"(b) conv\", fontsize=10)\n",
    "subset_conv = subset[subset[\"domain\"] == \"conv\"]\n",
    "sns.lineplot(subset_conv, x=\"doc_position\", y=\"is_present\", hue=\"model\", ax=ax)\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.10))\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "\n",
    "ax.grid(axis='y', which=\"major\", linewidth=1, linestyle='--', color=\"gray\")\n",
    "\n",
    "ax.set_xlabel(\"Document Position\")\n",
    "ax.set_ylabel(None)\n",
    "\n",
    "ax.set_ylim((0.0, 0.5))\n",
    "ax.set_xlim((0.0, 9))\n",
    "ax.legend(loc=\"upper left\", ncols=2, bbox_to_anchor=(0.0, 1.0), fontsize=7.5)\n",
    "\n",
    "remove_axes(ax)\n",
    "adjust(fig, hspace=0.2)\n",
    "save_fig(fig, f\"both_domains__subtopic_trustworthy__fc+pc__{COMBINATION_SIZE}.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5102b4-180b-44ab-93d2-35f9468b315a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7782cca-013e-47ff-9999-e7330dae258a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90653539-3704-4880-b168-bd91e0e04446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f6d18-5f23-4527-b8b4-52da6821c873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
